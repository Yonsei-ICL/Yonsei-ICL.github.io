---
layout: post
title: "A Probabilistic Perspective on Unlearning and Alignment for Large Language Models"
date: 2025-11-26
authors: ["승환 이"]
categories: ["research"]
conference: "ICLR'25"
description: "💡LLM이 언러닝, 정렬이 진짜 잘 됐는지 평가하기 위해선 기존의 결정론적 출력 즉, 하나의 답만 평가해선 안되고, 모델의 전체 출력 분포를 확률적으로 보고 평가를 해야 함이를 위해 새로운 기존의 결정론적인 평가지표가 아닌 새로운 확률론적인 평가 지표들을 제안"
image: /blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/thumbnails/thumbnail.png
---

<article id="2a407ee4-11c6-801b-9ca2-ec4f758dab5b" class="page sans"><header><h1 class="page-title" dir="auto"><strong><a href="https://arxiv.org/abs/2410.03523">A Probabilistic Perspective on Unlearning and Alignment for Large Language Models</a></strong></h1><p class="page-description" dir="auto"></p></header><div class="page-body"><div style="display:contents" dir="auto"><h2 id="2ab07ee4-11c6-8017-af42-da1b128d5c8b" class="">Review </h2></div><div style="display:contents" dir="ltr"><table id="2ab07ee4-11c6-802c-b50b-f6431704a5b3" class="simple-table"><thead class="simple-table-header"><div style="display:contents" dir="ltr"><tr id="2ab07ee4-11c6-80a0-896c-e35f8f98d6fe"><th id="DPUd" class="simple-table-header-color simple-table-header" style="width:114.32499694824219px">닉네임 </th><th id="`?[S" class="simple-table-header-color simple-table-header" style="width:455.32501220703125px">한줄평</th><th id="~yI=" class="simple-table-header-color simple-table-header" style="width:131.3249969482422px">별점 (0/5)</th></tr></div></thead><tbody><div style="display:contents" dir="ltr"><tr id="2ab07ee4-11c6-80b7-ac09-fa094893be58"><td id="DPUd" class="" style="width:114.32499694824219px">MNG</td><td id="`?[S" class="" style="width:455.32501220703125px">기존 언러닝의 평가 방법이 가진 문제점을 잘 짚은 것 같음. 이제는 LLM을 평가하는 것에 있어 결과보다는 과정까지 이해해보려는 노력이 많은 것 같음.</td><td id="~yI=" class="" style="width:131.3249969482422px">4</td></tr></div><div style="display:contents" dir="ltr"><tr id="2ab07ee4-11c6-8099-b6b1-d019fca90854"><td id="DPUd" class="" style="width:114.32499694824219px">오차즈케</td><td id="`?[S" class="" style="width:455.32501220703125px">LLM의 unlearning과 alignment를 통합하여 하나의 확률적 관점으로 바라본다는 점이 신선함. 또한 여러개의 평가지표를 통해 정교하게 측정할 수 있는 것 같음. 이쪽 분야 논문들에 아직 익숙하진 않지만, 이러한 결과들을 어떻게 측정하려는지도 하나의 큰 task인것 같음.</td><td id="~yI=" class="" style="width:131.3249969482422px">4</td></tr></div><div style="display:contents" dir="ltr"><tr id="2b607ee4-11c6-80d1-b06a-db7c8e20ef88"><td id="DPUd" class="" style="width:114.32499694824219px">42REN</td><td id="`?[S" class="" style="width:455.32501220703125px">LLM의 기존 평가 방법의 문제점이 잘 드러나있는 논문임. 한 번의 출력으로는 LLM의 신뢰성을 평가하기 어려운 부분이 있는데, Unlearning이 잘 되었는지 확률 분포를 지표로 활용함으로써 이 문제 해결에 대한 실마리가 될 것 같음.</td><td id="~yI=" class="" style="width:131.3249969482422px">4</td></tr></div><div style="display:contents" dir="ltr"><tr id="2b607ee4-11c6-802a-8052-c5f95590f925"><td id="DPUd" class="" style="width:114.32499694824219px">텀블러</td><td id="`?[S" class="" style="width:455.32501220703125px">Unlearning과 Alignment는 교집합이 있긴 하지만(논문에서 언급하는 safety 관점) 크게 봤을 때 목적이 좀 다름. 논문에서는 두 주제를 비슷한 영역에서 다루긴 하지만 표현할 때 좀 더 specific하게 표현해야 하지 않았나 하는 생각이 듦. 모델 내 지식을 생성단에서 수학적으로 평가하는 것은 흥미로운 부분임.</td><td id="~yI=" class="" style="width:131.3249969482422px">3.5</td></tr></div><div style="display:contents" dir="ltr"><tr id="2b607ee4-11c6-80c4-bec8-f9deb71d436d"><td id="DPUd" class="" style="width:114.32499694824219px">감자</td><td id="`?[S" class="" style="width:455.32501220703125px">연구 동기가 방법론과 실험까지 잘 이어지는 듯하다. 엔트로피를 조절해서 답변의 랜덤성을 조절하고, temperature를 스스로 조절할 수 있게 하는 방식도 새로웠다</td><td id="~yI=" class="" style="width:131.3249969482422px">4</td></tr></div><div style="display:contents" dir="ltr"><tr id="2b607ee4-11c6-804a-8e1c-df27cc9b1457"><td id="DPUd" class="" style="width:114.32499694824219px">방어냠냠</td><td id="`?[S" class="" style="width:455.32501220703125px">결국 unlearning은 분포를 건들여야 한다는 점을 명확하게 꼬집어내고, 이를 엔트로피와 접목시켜 다양한 지표로 잘 풀어낸듯! 깔끔하고 군더더기 없는 논문이당 </td><td id="~yI=" class="" style="width:131.3249969482422px">4</td></tr></div><div style="display:contents" dir="ltr"><tr id="2b607ee4-11c6-8010-92d1-d51dce0fb08d"><td id="DPUd" class="" style="width:114.32499694824219px">새우</td><td id="`?[S" class="" style="width:455.32501220703125px">Unlearning과 Alignment가 ‘원하지 않는 출력 분포를 줄이고, 원하는 영역의 분포는 유지하자’라는 공통 motivation을 가지고 엔트로피 최적화를 수행한점이 인상적임. 4가지 확률 지표는 교수님께서 보내주신 leakage 문제를 다룰 때 적용해볼 수 있지 않을까?</td><td id="~yI=" class="" style="width:131.3249969482422px">4</td></tr></div><div style="display:contents" dir="ltr"><tr id="2b707ee4-11c6-805f-8f67-f6f74599fc37"><td id="DPUd" class="" style="width:114.32499694824219px">야키토리</td><td id="`?[S" class="" style="width:455.32501220703125px">확률론적으로 출력을 했다면 평가 또한 확률론적으로 샘플링해야된다는 아이디어가 새로웠고 실제로 정보 유출을 줄이기 위해 엔트로피와 온도를 조절해서 하는게 인상 깊었던 논문. 다만 alignment에 대한 설명이 부족해서 그냥 언러닝만으로 갔어도 됐을 것 같다.</td><td id="~yI=" class="" style="width:131.3249969482422px">3.5</td></tr></div></tbody></table></div><div style="display:contents" dir="auto"><h2 id="2ab07ee4-11c6-80e1-a77a-c425fb53aebe" class="">TL; DR</h2></div><div style="display:contents" dir="ltr"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="2ab07ee4-11c6-80e2-8bea-c569cfafb8ea"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%"><div style="display:contents" dir="auto"><p id="2ab07ee4-11c6-8077-a54b-c657134124f3" class="">LLM이 언러닝, 정렬이 진짜 잘 됐는지 평가하기 위해선 기존의 <strong>결정론적 </strong>출력 즉, 하나의 답만 평가해선 안되고, 모델의 전체 출력 분포를 <strong>확률적</strong>으로 보고 평가를 해야 함</p></div><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-8069-ad2c-fad55fc3d65a" class="">이를 위해 새로운 기존의 결정론적인 평가지표가 아닌 새로운 확률론적인 평가 지표들을 제안</p></div></div></figure></div><div style="display:contents" dir="auto"><h1 id="2ab07ee4-11c6-80a7-9fd1-db6958dca7b8" class="">Summary </h1></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80a2-a31c-e0f20afd1ead" class="bulleted-list"><li style="list-style-type:disc">연구진: 뮌헨 공과대학교</li></ul></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80f9-9c1e-d82406728543" class="bulleted-list"><li style="list-style-type:disc">인용수: 24</li></ul></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80f4-82a4-fa7894f598c2" class="bulleted-list"><li style="list-style-type:disc">개인적으로 생소한 주제 + 수식이 너무 많아서 읽는데 한참 걸렸지만 알아가는게 많았던 논문</li></ul></div><div style="display:contents" dir="auto"><ul id="2b507ee4-11c6-80eb-8337-df3626883d12" class="bulleted-list"><li style="list-style-type:disc">그 동안에 평가 지표를 그리디하게 보는 것을 당연하게 생각했었는데, 출력을 확률 분포에서 샘플링했다면 평가 또한 그리디한 평가가 아닌 확률 분포를 지표로 봐야한다는 점이 평소에 생각 못한 부분이라 인상적임</li></ul></div><div style="display:contents" dir="auto"><h2 id="2b307ee4-11c6-80ba-ac6f-f368d5a636bf" class="block-color-gray_background">1. Introduction</h2></div><div style="display:contents" dir="auto"><h3 id="2b307ee4-11c6-8014-bfab-dc02353e4143" class="block-color-orange_background">1.1 Background</h3></div><div style="display:contents" dir="auto"><h3 id="2b307ee4-11c6-80dc-b4b2-d78bd101c3bd" class="">언러닝의 등장</h3></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-807b-8406-e88f22395e14" class="bulleted-list"><li style="list-style-type:disc">목표: 학습된 정보 중 잊고자 하는 정보를 지우는 것 </li></ul></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80cd-8650-e97af58aaea7" class="bulleted-list"><li style="list-style-type:disc"><strong>재학습</strong>(Retraining): 기존 방식, <strong>지우고자 하는 데이터를 제외</strong>하고 <strong>처음부터 다시 학습</strong>하는 방식<div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-803d-b6d2-edcdca66ad64" class="bulleted-list"><li style="list-style-type:circle">단점: 학습 비용이 너무 크고 오래 걸림 ⇒ 언러닝의 등장!</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-8042-96cf-f7a594c63006" class="bulleted-list"><li style="list-style-type:disc"><strong>언러닝(Unlearning): </strong>재학습을 하지 않고 이미 학습된 정보 중 <strong>일부 정보만 선택적으로 </strong>지우는 학습<div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80dd-8bc4-fd7dc9c8d950" class="bulleted-list"><li style="list-style-type:circle"><strong>목표: 특정 정보를 지우되, </strong>나머지 <strong>성능은 최대한 유지하는 것</strong></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80ae-aaf5-ee51e9489b08" class="bulleted-list"><li style="list-style-type:disc">언러닝 연구의 view point🤔<div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80e3-aa88-e7b62d6d5a26" class="bulleted-list"><li style="list-style-type:circle"><strong>“재학습한 모델”과 “언러닝한 모델”의 출력이 얼마나 비슷한가?</strong></li></ul></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-803f-a3c6-c9ca5149589e" class="bulleted-list"><li style="list-style-type:circle"><strong>삭제 데이터에 대한 기억이 얼마나 사라졌는가?</strong></li></ul></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-8012-b7f6-e94eb583b94e" class="bulleted-list"><li style="list-style-type:circle"><strong>나머지 일반 벤치마크 성능은 얼마나 유지되는가?</strong></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><h3 id="2b307ee4-11c6-80a6-be5b-cb9eb75d2f3e" class="block-color-orange_background">1.2 Motivation</h3></div><div style="display:contents" dir="auto"><h3 id="2b307ee4-11c6-808c-b630-cd4455961902" class="">기존 평가 방식의 문제점 (확률론적인 출력 but 결정론적인 평가)</h3></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80f4-b0f4-c052bc46e409" class="bulleted-list"><li style="list-style-type:disc">Beam Search, Multinomial Sampling 과 같은 방식은 <strong>확률적 디코딩 방법</strong>을 통해 <strong>출력</strong>을 생성</li></ul></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80a2-95c2-cec2702cbf00" class="bulleted-list"><li style="list-style-type:disc">하지만 <strong>LLM의 성능 평가</strong>는 주로 <strong>greedy decoding</strong>으로 생성된 <strong>결정론적 출력</strong>에 의존<div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80de-8637-d19001fedd28" class="bulleted-list"><li style="list-style-type:circle">greedy decoding: 딱 한 번만 답을 뽑아서 그걸로만 성능을 측정</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="e19ed936-d2e3-4a4b-ad48-7f981bce86ae" class="bulleted-list"><li style="list-style-type:disc"><strong>언러닝(Unlearning)</strong>: 모델이 특정 정보를 <strong>정말 잊었는지</strong> 평가해야 함</li></ul></div><div style="display:contents" dir="auto"><ul id="b775be3c-7c3a-4f01-9b39-0d9c404d3547" class="bulleted-list"><li style="list-style-type:disc"><strong>정렬(Alignment)</strong>: 모델이 <strong>해로운 답변을 실제로 안 하는지</strong> 평가해야 함</li></ul></div><div style="display:contents" dir="auto"><p id="2b307ee4-11c6-8028-83d0-f0b09c8956bb" class="">⇒ <code>RQ</code> 결정론적인 평가만으로 언러닝과 정렬이 잘 되었는지 확인할 수 있을까?<div class="indented"><div style="display:contents" dir="ltr"><figure id="2b307ee4-11c6-809a-a44f-ca8d656b186e" class="image"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image.png"><img style="width:709.9431762695312px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image.png"/></a><figcaption>1. 지워야 할 정보: Harry Potter의 best friends(Ron&amp;Hermione)<br/>2. 결정론적 출력(왼쪽 그래프)의 경우 정보 누출을 John and  Peter를 출력하여 언러닝에 성공했다고 생각할 수 있지만,      실제로 확률적인 분포로 평가할 경우 정보 누출을 파란 배경의 그래프와 같은 정보 누출이 확인됨</figcaption></figure></div></div></p></div><div style="display:contents" dir="auto"><h3 id="2b307ee4-11c6-80f2-bc01-d81b7b11e34e" class="">확률론 관점의 언러닝</h3></div><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-80a4-8e31-fdb3f6a17c5e" class="bulleted-list"><li style="list-style-type:disc"><strong>지워야 할 데이터 D를 포함해서 학습한 출력 분포</strong> vs <strong>D를 포함하지 않고 학습한 출력 분포</strong><div style="display:contents" dir="auto"><ul id="2b307ee4-11c6-808e-b999-c6d04aa2fdcc" class="bulleted-list"><li style="list-style-type:circle">두 분포의 차이를 줄여주는 방향으로 손실 함수를 정의하거나 gradient 업데이트를 설계해야 함<div style="display:contents" dir="auto"><p id="2b307ee4-11c6-80ae-ad58-c6653bb654be" class="">⇒ retraining 을 하지 않고도 <strong>“D를 빼고 학습한 모델”에 가깝게 </strong>만드는 것</p></div></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="c72cc781-abfe-4173-b9c4-d555592efdf6" class="bulleted-list"><li style="list-style-type:disc">기존 모델 파라미터 <strong>θ_old</strong>, D 언러닝 후 파라미터 <strong>θ_unlearn</strong>, D를 제외하고 재학습하여 얻은 이상적인 파라미터 θ* 가 있다고 할 때,<div style="display:contents" dir="auto"><p id="55812cce-60dd-4a59-a020-47cc5a51ee9b" class=""><strong>⇒ 목표: 재학습 없이 θ_old → θ_unlearn</strong> 로 만들고 <strong>θ_unlearn ≈ θ* 가 되도록 </strong>학습</p></div></li></ul></div><div style="display:contents" dir="auto"><h3 id="2b307ee4-11c6-80ae-b362-d81959ccd1b7" class="block-color-orange_background">1.3 Contribution</h3></div><div style="display:contents" dir="auto"><ul id="a0dab178-74f2-452a-8f75-2e62e305b7b6" class="bulleted-list"><li style="list-style-type:disc"><strong>멀티노미얼 샘플링</strong>만으로도<strong> </strong>최신 언러닝/정렬 모델에서 언러닝된 정보, 유해 정보를 감지 가능함을 보임</li></ul></div><div style="display:contents" dir="auto"><ul id="13ab4acc-725a-4307-8a84-bdc7271b3637" class="bulleted-list"><li style="list-style-type:disc">LLM 평가를 <strong>확률적 관점에서 모델링한 첫 연구로,</strong> 기존의 결정론적인 greedy 기반 평가 방식보다 확률론적인 평가 방식이 <strong>정보 유출</strong>을 더 잘 포착함을 입증</li></ul></div><div style="display:contents" dir="auto"><ul id="cc220aa9-8450-4562-9155-1b556e11c350" class="bulleted-list"><li style="list-style-type:disc">출력 분포를 비교하기 위한, <strong>고확률(high-probability) 보장</strong>을 제공하는 네 가지 <strong>확률적 평가 지표</strong>(Mbin, Mgen, Mμ, Mσ)와 개발용 간단 지표(ED score)를 제안</li></ul></div><div style="display:contents" dir="auto"><ul id="8949a1b0-a598-4cd6-a662-c8fd63cd6e10" class="bulleted-list"><li style="list-style-type:disc">분포 차원에서 언러닝을 더 안전하게 만들기 위해(정보 누출을 잘 막기 위해) 아래와 같은 두 방법론 제안<div style="display:contents" dir="auto"><ul id="7f823fcc-7117-47ac-9025-022a76535eaa" class="bulleted-list"><li style="list-style-type:circle">(1) <strong>엔트로피 최적화 기반 새로운 손실 함수</strong></li></ul></div><div style="display:contents" dir="auto"><ul id="b8a623af-63cd-4da9-9473-52a64873d6fb" class="bulleted-list"><li style="list-style-type:circle">(2) <strong>Adaptive Temperature Scaling </strong></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><h2 id="2b307ee4-11c6-80ef-8ecb-e1562d8699eb" class="block-color-gray_background">2. Methods</h2></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-802e-b14c-dabd069cb835" class="bulleted-list"><li style="list-style-type:disc">기존의 평가 지표들은 답변 1개만 확인하여 평가 → 운이 좋으면 통과 나쁘면 통과 X</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8052-96f0-c40f0e399bdc" class="bulleted-list"><li style="list-style-type:disc">답변을 여러 번 시켜보고 (몬테카를로 샘플링), 정보 유출의 위험도를 수학적으로 나타내는 지표를 제시</li></ul></div><div style="display:contents" dir="auto"><h3 id="2b407ee4-11c6-80c5-9dd0-cdbaf47bf3e0" class="block-color-orange_background">2.1 변수 세팅</h3></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80c0-8395-f9d503d6c14e" class="bulleted-list"><li style="list-style-type:disc"><strong>q</strong>: 프롬프트 (정보 유출을 이끌어 내기 위한 질문) e.g., 해리포터의 베프는 누구냐?!</li></ul></div><div style="display:contents" dir="auto"><ul id="eb2b4593-620d-4305-981b-15413f62f98c" class="bulleted-list"><li style="list-style-type:disc"><strong>Y ~ πθ(q)</strong>: LLM이 q에 대한 출력 분포에서 샘플링한 하나의<strong> 답변 시퀀스 </strong>(토큰 여러 개로 이루어진 문장)</li></ul></div><div style="display:contents" dir="auto"><ul id="bbe01243-84df-4d4a-bbf6-c24328ebca57" class="bulleted-list"><li style="list-style-type:disc"><strong>Y₁,…,Yₙ ~ πθ(q): </strong>LLM을 n번 호출해서, 프롬프트 q에 대한 답변 n개를 샘플링한 것</li></ul></div><div style="display:contents" dir="auto"><ul id="84959910-125e-4992-8014-374e08761da7" class="bulleted-list"><li style="list-style-type:disc"><strong>Xᵢ = h(Yᵢ)</strong>:  랜덤하게 하나의 답변 Y를 뽑았을 때, 그 답변의 <strong>유출 정도</strong>를 나타내는 <strong>확률변수</strong><div style="display:contents" dir="auto"><ul id="5ae4df7f-f7aa-42ad-b7f0-1f0ad70a756c" class="bulleted-list"><li style="list-style-type:circle"><strong>X= </strong>h(Y) = 0: 정보 누출 없음</li></ul></div><div style="display:contents" dir="auto"><ul id="a7578db0-99eb-4c1b-8595-eeb14e767723" class="bulleted-list"><li style="list-style-type:circle"><strong>X =</strong>h(Y) = 1: 완전 누출</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="ff57b52f-91c8-49fa-a992-42f24e48eb85" class="bulleted-list"><li style="list-style-type:disc"><strong>M(X₁,…,Xₙ)</strong>: X₁,…,Xₙ을 입력으로 넣어 정의한 metric M(Mbin, Mgen, Mμ, Mσ)을 계산한 것</li></ul></div><div style="display:contents" dir="auto"><h3 id="b2cbecda-c651-448f-b885-c0e13579421b" class="block-color-orange_background">2.2 LLM 평가를 위한 4<strong>+ 1</strong>가지 확<strong>률적 평가 지표</strong></h3></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-806c-a9b3-cb00bb7c7c35" class="bulleted-list"><li style="list-style-type:disc">아래의 총 4개의 <strong>Evaluation Metric</strong>을 제안<div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-809a-8417-f266457490db" class="image"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%201.png"><img style="width:192px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%201.png"/></a></figure></div></li></ul></div><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-8011-a2fc-e0484ed27e04" class="numbered-list" start="1"><li><strong>Mbin (Binary leakage bound)</strong><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80b6-87e4-f76106373876" class="bulleted-list"><li style="list-style-type:disc">목적:  한번 더 답변을 샘플링했을 때, <strong>유출이 한 번이라도 일어날 확률</strong>의 상한에 대한 지표(이진 상황)<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80dc-bee3-dce54d551b65" class="bulleted-list"><li style="list-style-type:circle"><strong>n번 실험 후, 유출된 횟수를 세어서</strong> 다음 답변이 유출될 확률의 최댓값을 계산</li></ul></div><div style="display:contents" dir="auto"><ul id="cf2e6c1b-7a49-429a-8937-0707a30b96f7" class="bulleted-list"><li style="list-style-type:circle">정답 키워드가 포함되면 → <code>X=h(Y)=1</code> (유출 O)</li></ul></div><div style="display:contents" dir="auto"><ul id="3284d419-bb4a-4449-ad6f-11e4fd933d33" class="bulleted-list"><li style="list-style-type:circle">포함되지 않으면 → <code>X=h(Y)=0</code> (유출 X)</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="ca5c9ef8-57c0-4841-b219-e91903445256" class="bulleted-list"><li style="list-style-type:disc">유출 정도를 나타내는 X<em>i</em>∈{0,1} 는 <strong>베르누이 확률변수,</strong>임의의 답변 1개에서 정보가 누출될 확률 p</li></ul></div><div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-8061-a1f7-cbe37ceb83dd" class="image" style="text-align:center"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%202.png"><img style="width:144px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%202.png"/></a></figure></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8016-9b56-cdeb9ae77d7e" class="bulleted-list"><li style="list-style-type:disc">샘플 n개에 대해</li></ul></div><div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-807e-839b-c42d67085523" class="image"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%203.png"><img style="width:96px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%203.png"/></a></figure></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-802a-b2d4-cd62ac5e2513" class="bulleted-list"><li style="list-style-type:disc">S<strong>ₙ</strong>: <strong>유출이 발생한 샘플의 개수 </strong>e.g., n=100, 그 중 3개 답이 정답 키워드를 포함 → S<strong>ₙ</strong>=3</li></ul></div><div style="display:contents" dir="auto"><ul id="bc9f7443-610c-474a-be5c-7129d05fde9b" class="bulleted-list"><li style="list-style-type:disc"><strong>다음 한 번의 샘플에서 샐 확률 p</strong>의 상한</li></ul></div></li></ol></div><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-8016-b21e-c03a58dc8b2a" class="numbered-list" start="2"><li><strong>Mgen (General leakage bound)</strong></li></ol></div><div style="display:contents" dir="auto"><ul id="7e920fc0-8d5e-4c30-8b44-b08d4441704a" class="bulleted-list"><li style="list-style-type:disc"><strong>목적: 유출 정도가 τ 이상인 유출이 다음 번에 나올 확률은 최대 얼마인가?</strong> 에 대한 지표</li></ul></div><div style="display:contents" dir="auto"><ul id="2b707ee4-11c6-802d-838e-d5559bd8a0c2" class="bulleted-list"><li style="list-style-type:disc">세팅:<div style="display:contents" dir="auto"><ul id="f67bb22a-4b38-4654-aa7e-6c0dfcae7f98" class="bulleted-list"><li style="list-style-type:circle">유출 정도를 연속 값으로 측정:</li></ul></div><div style="display:contents" dir="auto"><ul id="2b707ee4-11c6-8006-a7d8-c2b4c0f1f5b2" class="bulleted-list"><li style="list-style-type:circle">X=h(Y)∈[0,1]<div style="display:contents" dir="auto"><ul id="1f87480c-8940-4f13-ab28-2689bcc1e180" class="bulleted-list"><li style="list-style-type:square">0.0 → 전혀 안 새었음</li></ul></div><div style="display:contents" dir="auto"><ul id="3611a730-5a79-4f13-b3cf-ca8c74052b81" class="bulleted-list"><li style="list-style-type:square">0.3 → 살짝 비슷</li></ul></div><div style="display:contents" dir="auto"><ul id="2d5ca83e-e5fa-4ee5-87d2-b723e0ba1caf" class="bulleted-list"><li style="list-style-type:square">0.8 → 거의 그대로 말함</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="01f08a10-2921-4413-8cc4-224ca0569556" class="bulleted-list"><li style="list-style-type:circle">기준값 x를 정하고,Pr(X&gt;x)<div style="display:contents" dir="auto"><p id="08e596d9-fc06-49e0-862e-a8805feb3a5d" class="">= “누출 정도가 x를 초과하는 <strong>심각한 유출</strong>이 발생할 확률을 구함</p></div></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-80da-a7f7-eae499d84984" class="numbered-list" start="3"><li><strong>Mμ (Expectation bounds, 기대 유출 상한)</strong></li></ol></div><div style="display:contents" dir="auto"><ul id="29dca344-be2d-4f92-876c-9419bc7a9fae" class="bulleted-list"><li style="list-style-type:disc">이 프롬프트에 대해 <strong>평균적으로 어느 정도의 유출 정도</strong>를 갖는지를 평가하는 지표<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80ad-a0d1-f9ee772d4fdd" class="bulleted-list"><li style="list-style-type:circle">X의 기댓값(평균 정보 유출량)의 상한선 제공</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-806c-81e2-c330260e21cf" class="bulleted-list"><li style="list-style-type:disc">구간 [0,1]을 K개의 구간으로 나누고, 각 구간에 대해 경험적 CDF 값을 이용해 다음과 같이 계산</li></ul></div><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-807a-a199-d62b5ba2919d" class="numbered-list" start="4"><li><strong>Mσ (Standard deviation bound, 표준편차 상한)</strong><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8098-8df1-ec8ee3db9ef7" class="bulleted-list"><li style="list-style-type:disc">평균만 보고 알 수 없는 <strong>유출 정도의 표준편차에 대해 상한</strong>을 제공<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80ed-8464-dc457a2c2590" class="bulleted-list"><li style="list-style-type:circle">유출 점수가 얼마나 불확실(들쭉날쭉)한지 알고 싶을 때</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8048-b6be-c6d807319f00" class="bulleted-list"><li style="list-style-type:disc">답변의 변동성, 표준편차가 아무리 커도 Mσ보다는 작을 것이라는 상한선 설정<div style="display:contents" dir="auto"><ul id="b3036ed9-236c-4af1-bbd7-3c632a476d71" class="bulleted-list"><li style="list-style-type:circle">Mσ값이 크면 들쭉날쭉하게 정보를 유출 할 수 있는 모델</li></ul></div><div style="display:contents" dir="auto"><ul id="09b66241-d20d-4401-905e-952b548f1fa0" class="bulleted-list"><li style="list-style-type:circle">Mσ값이 작으면 비슷한 정도의 정보를 유출하는 모델</li></ul></div></li></ul></div></li></ol></div><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-80cd-ad03-c7f5c599aad5" class="numbered-list" start="5"><li>ED score<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-806b-82b0-fe21793890a2" class="bulleted-list"><li style="list-style-type:disc">목표: 개발 중에 간단하게 사용할<strong> 빠르고 간단한</strong> 지표 ED score 제안<div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-806c-8277-f5bc6af0a92c" class="image"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%204.png"><img style="width:336px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%204.png"/></a></figure></div></li></ul></div><div style="display:contents" dir="auto"><ul id="483aca76-c5a9-411e-a036-0232355d3689" class="bulleted-list"><li style="list-style-type:disc"><strong>Smean:</strong> 평균적으로 얼마나 유출하는가?</li></ul></div><div style="display:contents" dir="auto"><ul id="3e6ef702-4e70-494f-bc88-0d3e965c03b9" class="bulleted-list"><li style="list-style-type:disc"><strong>Ssd:</strong> 가끔 튀는 유출(표준 편차)이 어느정도인가?</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-804e-86c6-dd0a0a491cfc" class="bulleted-list"><li style="list-style-type:disc">ρ: 평균과 표준편차의 비중을 조절하는 하이퍼파라미터 (본 논문에서 ρ=2 사용)<div style="display:contents" dir="auto"><p id="2b407ee4-11c6-8083-a340-d86c4550be6d" class="">→ ED score 점수가 낮을수록 평균 유출도 작고 가끔 크게 새는 케이스도 적다는 뜻 → 언러닝 good!</p></div></li></ul></div></li></ol></div><div style="display:contents" dir="auto"><h3 id="2b307ee4-11c6-80a5-8b5b-c157f34ca182" class="block-color-orange_background">2.3 엔트로피 최적화 + 온도 스케일링에 의한 분포 언러닝</h3></div><div style="display:contents" dir="auto"><ul id="b0d3e63e-f9cc-460b-8459-e2c0a2335b5c" class="bulleted-list"><li style="list-style-type:disc"><strong>기존 언러닝 평가 문제점:</strong> 모델이 가장 높은 확률로 내놓는 답변(Greedy output)에만 집중함 </li></ul></div><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-80f7-9460-e51a43450d0e" class="">       → 하지만 실제로는 <strong>샘플링</strong>(temperature, top-p 등)를 많이 사용 <div class="indented"><div style="display:contents" dir="auto"><p id="2b707ee4-11c6-808f-81b2-d3682d7fb33d" class="">→ 그리드한 출력 평가로는 유출이 안된것처럼 보여도 <strong>샘플링하면 유출</strong>되는 경우가 많음</p></div><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-804b-b596-e6e1d3f3cde5" class=""><strong>⇒ 하나의 정답에 대한 학습이 아닌 분포 자체가 안전하게 만들도록 학습시키자!</strong></p></div></div></p></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8020-85c6-d948bac2f866" class="bulleted-list"><li style="list-style-type:disc"><strong>1. 엔트로피 최적화</strong><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8002-8c41-ceaeccc789ba" class="bulleted-list"><li style="list-style-type:circle">목표: 잊어야 할 정보(forget set)은 불확실성을 최소화하고, 일반 정보(retain set)은 창의성 유지</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80ad-9263-d680753c3bf3" class="bulleted-list"><li style="list-style-type:circle">forget set(DFG):<div style="display:contents" dir="auto"><ul id="2b707ee4-11c6-803a-824f-d139f2f2f4b4" class="bulleted-list"><li style="list-style-type:square">엔트로피를 줄여서 샘플링을 해도 정보 누출이 안되도록</li></ul></div><div style="display:contents" dir="auto"><p id="2b707ee4-11c6-8074-b4f6-d587a7e3075b" class=""> → 샘플링을 해도 계속 비슷한 안전 답만 나오게 만들기</p></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8040-bdc6-f2d3cf1bb6e4" class="bulleted-list"><li style="list-style-type:circle">Retain set(DFT):<div style="display:contents" dir="auto"><ul id="2b707ee4-11c6-80e7-832d-eb238ad38fe9" class="bulleted-list"><li style="list-style-type:square">엔트로피를 늘려서 기존처럼 다양한 답, 창의성을 유지</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><p id="2b707ee4-11c6-803d-81e3-cb35a6231015" class="">
</p></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80ec-a8a0-cc79cc48c009" class="bulleted-list"><li style="list-style-type:circle"><strong>평균 토큰 엔트로피 손실 함수</strong>를 통해 <strong>전체 토큰에 대한 평균 손실</strong>을 구함</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8007-9a34-cef56ab3499f" class="bulleted-list"><li style="list-style-type:circle">토큰 분포 q=πθ(⋅∣y&lt;t,x) 의 엔트로피:<div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-805c-958c-caa810b6c986" class="image" style="text-align:center"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%205.png"><img style="width:192px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%205.png"/></a><figcaption>               엔트로피 함수</figcaption></figure></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80dc-a055-e9b01edc1a98" class="bulleted-list"><li style="list-style-type:circle">길이 m인 시퀀스 (x,y)에 대한 평균 토큰 엔트로피 손실<div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-8090-9247-ef07876f8917" class="image" style="text-align:center"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%206.png"><img style="width:336px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%206.png"/></a><figcaption>                          평균 토큰 엔트로피 손실함수</figcaption></figure></div></li></ul></div><div style="display:contents" dir="auto"><ul id="e52b4f02-3282-4606-8afd-1226eef6769f" class="bulleted-list"><li style="list-style-type:circle">Forget / Retain Set에 대한 기대 엔트로피<div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-80a6-a2f0-d8f0fa6dffe1" class="image" style="text-align:center"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%207.png"><img style="width:411.875px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%207.png"/></a></figure></div></li></ul></div><div style="display:contents" dir="auto"><ul id="3dd19515-9036-4131-a096-d6e4d65804d9" class="bulleted-list"><li style="list-style-type:circle">DFG에서 엔트로피가 <strong>크면 </strong>E<em>DFG</em>[ℓθ(x,y)]가 커지고<div style="display:contents" dir="auto"><p id="c28226b2-2cf0-45de-af6f-669fd5e2358a" class="">→ λf&gt;0이므로 <strong>전체 손실 LEO도 커짐</strong></p></div><div style="display:contents" dir="auto"><p id="3c1533d2-4b7c-494c-bc90-63575f4f3056" class="">→ <strong>DFG의 엔트로피를 줄이는 방향</strong>으로 파라미터를 업데이트</p></div><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-80d7-83f8-e3432b44fb03" class="">→ DFG 출력의 랜덤성을 완화하는 것임 </p></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80c0-95df-fefd57e434ae" class="bulleted-list"><li style="list-style-type:circle">문제는 엔트로피를 그냥 낮춰버리면 모든 질문에 대한 답이 단조로워지고 창의성이 떨어짐<div style="display:contents" dir="auto"><p id="2b407ee4-11c6-80fd-b3fc-f3e696bdbcee" class="">→ DRT에 대한 엔트로피를 약간 늘리도록 가중치를 둠</p></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80a6-9a0d-cd0ae8630e68" class="bulleted-list"><li style="list-style-type:circle">최종 손실 함수<div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-8074-9380-fb4971b15f78" class="image" style="text-align:center"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%208.png"><img style="width:576px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%208.png"/></a></figure></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8018-8624-d5a9201c5b9b" class="bulleted-list"><li style="list-style-type:square">LUL(θ): 기존 언러닝 손실 (예: NPO)</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8043-8f03-f88a2579d554" class="bulleted-list"><li style="list-style-type:square">λf&gt;0: DFG의 엔트로피를 <strong>줄이려는</strong> 가중치</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8089-92f1-fdbc1bfc32b9" class="bulleted-list"><li style="list-style-type:square">λr&lt;0: DRT의 엔트로피를 <strong>약간 늘리려는</strong> 가중치 (음수)</li></ul></div><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-80d0-8cc3-c081f865d510" class="">
</p></div></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-80e9-9143-c9905763b873" class=""><strong>2. 적응형 온도 조절(Adaptive Temperature Scaling)</strong><div class="indented"><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80c7-a6a7-dcacaefc1ba1" class="bulleted-list"><li style="list-style-type:disc">목표: 모델이 민감한 질문을 받았을 때, <strong>스스로 위험을 감지하고</strong> 정보 유출 가능성을 원천 차단</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8063-a33d-d89b1d6e242b" class="bulleted-list"><li style="list-style-type:disc"><strong>모델이 입력 x에 대한 확신이 있을 때, 온도를 0으로 낮춰</strong> 결정적인(greedy) 출력을 하도록 유도<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80e9-b20e-c0239f581880" class="bulleted-list"><li style="list-style-type:circle">확신이 적을 때만 <strong>샘플링 기법을 사용</strong>하여 정보 누출을 줄임</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8085-b0de-dd6eb6b8f829" class="bulleted-list"><li style="list-style-type:disc">입력 x에 대해 생성된 시퀀스의 <strong>각 토큰에서 등장 확률이 가장 높은 토큰 yt^의 확률</strong>: p(yt^∣y&lt;t,x) </li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80a9-91e4-d7c8cf75dea8" class="bulleted-list"><li style="list-style-type:disc"><strong>전체 시퀀스의 평균 확신도 공식</strong><div style="display:contents" dir="auto"><ul id="65ae5be4-2a5d-4652-9bd7-98887eaa2e47" class="bulleted-list"><li style="list-style-type:circle">y^t: 입력 x에 대해 생성된 시퀀스의 각 위치에서 확률이 가장 높은 토큰</li></ul></div><div style="display:contents" dir="auto"><ul id="2b707ee4-11c6-8098-af6a-c89b08138cae" class="bulleted-list"><li style="list-style-type:circle">p(y^t | y&lt;t, x) : y^t의 등장 확률</li></ul></div><div style="display:contents" dir="auto"><ul id="2b707ee4-11c6-803a-a8a8-e623823acb44" class="bulleted-list"><li style="list-style-type:circle">→ 각 토큰의 p(y^t∣y&lt;t,x) 값을 평균 내어 시퀀스의 평균 확신도를 계산</li></ul></div><div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-8004-a83f-fd6e412ee30f" class="image" style="text-align:center"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%209.png"><img style="width:288px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%209.png"/></a></figure></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80a3-b018-efdf67fc02b3" class="bulleted-list"><li style="list-style-type:disc">특정 기준점(threshold cT)를 두어 c(x)값이 cT를 넘으면 τ=0, 아니면 기본 값으로 설정하였음 </li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8010-8b01-eb1f17f7a396" class="bulleted-list"><li style="list-style-type:disc">→ 민감한 질문일 때만 온도를 0으로 낮춰(Adaptive) 정보 누출을 줄이고 출력 다양성에는 영향 X</li></ul></div></div></p></div><div style="display:contents" dir="auto"><h2 id="2b407ee4-11c6-80ac-b6cc-ce6dcd6f719e" class="block-color-gray_background">3. Experiments</h2></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8019-9d51-dc4388aaa298" class="toggle"><li><details open=""><summary><strong>experimental setup</strong></summary><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-807f-9830-fac4ea1a304a" class="numbered-list" start="1"><li>Unlearning Settings<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-804c-a6fe-e218690faf82" class="bulleted-list"><li style="list-style-type:disc">데이터셋<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8015-b281-c7dac7c35faa" class="bulleted-list"><li style="list-style-type:circle"><strong>TOFU</strong> (200명 가짜 작가 프로필):<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8046-8b5e-e73968e7cad1" class="bulleted-list"><li style="list-style-type:square">retain set: 유지해야 할 정보</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8032-86cc-c9ed71448fe8" class="bulleted-list"><li style="list-style-type:square">forget set: 지워야 할 정보</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8025-a0d9-e7c7e411b9cd" class="bulleted-list"><li style="list-style-type:circle">추가로 <strong>Real Authors, World Facts</strong> 데이터로 <strong>모델 유틸리티</strong> 측정</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8002-b947-d25a71930eb0" class="bulleted-list"><li style="list-style-type:circle">모델: <strong>Phi-1.5</strong></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80ee-aef5-dce60fcbab1e" class="bulleted-list"><li style="list-style-type:disc">추가 실험:<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-802a-925e-ff44eafa44d4" class="bulleted-list"><li style="list-style-type:circle"><strong>Llama-2-Who-is-Harry-Potter</strong>: Harry Potter 관련 지식을 지우도록 언러닝된 모델</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80cd-9737-ff2b1057a3c2" class="bulleted-list"><li style="list-style-type:circle">평가 데이터: <strong>Harry Potter Q&amp;A</strong> (질문 + 관련 키워드)</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80d3-ac89-eaa7e2273604" class="bulleted-list"><li style="list-style-type:disc">지표<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-800a-920c-f3902f0b5041" class="bulleted-list"><li style="list-style-type:circle"><strong>ROUGE-L</strong>:<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80c9-8b4c-c5b84ab98cd9" class="bulleted-list"><li style="list-style-type:square">정답 문장과 생성 문장 사이의 유사도</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8010-9f00-ed7c627bf1a5" class="bulleted-list"><li style="list-style-type:square">본 논문에서는 ROUGE-L 점수가 높다 ⇒ 정보 누출에 가깝다로 해석</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80b3-b55f-c19c95cc7b0a" class="bulleted-list"><li style="list-style-type:circle"><strong>self-BLEU</strong>:<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-808c-bef5-ce8979685f91" class="bulleted-list"><li style="list-style-type:square">생성된 여러 샘플끼리 BLEU를 측정하여 “서로 얼마나 비슷한가”를 비교</li></ul></div></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80f9-b0f4-e55b3a96e834" class="bulleted-list"><li style="list-style-type:disc">언러닝 베이스라인<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80c8-b658-c30e04b10524" class="bulleted-list"><li style="list-style-type:circle">Gradient Ascent (GA), Gradient Difference (GD), RMU, Negative Preference Optimization (NPO, SotA)</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-808f-8a20-e85a0179cec5" class="bulleted-list"><li style="list-style-type:circle">제안 방법은 <strong>NPO + 엔트로피 최적화 + 적응적 온도 조절</strong></li></ul></div></li></ul></div></li></ol></div><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-80cf-9fb9-c6598f5e05ec" class="numbered-list" start="2"><li><strong>Alignement Settings</strong><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8098-8b64-dabbf218c4f6" class="bulleted-list"><li style="list-style-type:disc">데이터: <strong>JailbreakBench(JBB)</strong> 의 100개 harmful behavior 질문</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80f2-a365-cf4f166a2f83" class="bulleted-list"><li style="list-style-type:disc">Alignment 측정<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8071-aabc-ca4f95e35f7b" class="bulleted-list"><li style="list-style-type:circle"><strong>Harmbench toxicity classifier</strong>가<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8099-af53-e510ddb35926" class="bulleted-list"><li style="list-style-type:square">모델 답변이 “유해하다고 판정될 확률”을 줌 → 이것을 toxicity score로 사용.</li></ul></div></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8032-807e-eab01be604d2" class="bulleted-list"><li style="list-style-type:disc">Models<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8017-86ab-f68b5e1cc866" class="bulleted-list"><li style="list-style-type:circle">Phi-1.5, Vicuna-7b-1.5, Mistral-7b-instruct-v0.3</li></ul></div></li></ul></div></li></ol></div></details></li></ul></div><div style="display:contents" dir="auto"><hr id="2b407ee4-11c6-8008-87c4-e8a11a7f4bed"/></div><div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-8027-a6a1-cc71501dbaa6" class="image"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%2010.png"><img style="width:720px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%2010.png"/></a><figcaption>                                                                                                    figure 3</figcaption></figure></div><div style="display:contents" dir="auto"><h3 id="2b407ee4-11c6-8032-8108-d91d7e12f70d" class=""><strong>Harry Potter Q&amp;A 에 대한 Mbin 결과</strong></h3></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-808d-8586-c64cab3e874a" class="bulleted-list"><li style="list-style-type:disc">figure 3-(a)  <div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80f2-9bfb-f5a10888cd68" class="bulleted-list"><li style="list-style-type:circle">x축: <strong>이진 누출 상한 지표 Mbin</strong> 값 (0~0.6 정도)<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8047-b033-c7fa46159011" class="bulleted-list"><li style="list-style-type:square">다음 샘플에서 정보가 샐 확률의 상한</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80bb-a9a8-d191ecb6c411" class="bulleted-list"><li style="list-style-type:circle">y축: 그 M_bin 값에 해당하는 <strong>질문의 비율</strong></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80ff-800e-f779b96bd701" class="bulleted-list"><li style="list-style-type:circle">파란색: 전통적인 <strong>그리디 평가</strong></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8034-b19a-d05570f8ccf3" class="bulleted-list"><li style="list-style-type:circle">주황색: <strong>샘플링 기반 확률적 평가</strong></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-807b-94e6-e80e6f656aa3" class="bulleted-list"><li style="list-style-type:circle">실험결과<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8022-a1d9-f253546528c1" class="bulleted-list"><li style="list-style-type:square">기존의 그리디 평가에서는 거의 모든 질문의 정보 누출이 0에 가까움</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8049-a05f-d6dc26bf16ab" class="bulleted-list"><li style="list-style-type:square">확률적 평가의 경우 38%의 질문이 누출이 되었음을 입증</li></ul></div></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><h3 id="2b407ee4-11c6-8054-894c-d7de106f8d66" class="">TOFU – 단일 질문에 대한 분포 분석</h3></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80b3-94e4-c1513a755b08" class="bulleted-list"><li style="list-style-type:disc">figure 3-(b,c)<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80e2-9795-dab5969748ab" class="bulleted-list"><li style="list-style-type:circle">같은 질문에 대해 1024개 샘플을 뽑고 각 샘플의 ROUGE-L 분포를 그림으로 표현<div style="display:contents" dir="auto"><ul id="fc8a7bbe-0b9b-42dc-9736-76a8521d3466" class="bulleted-list"><li style="list-style-type:square">x축: ROUGE-L</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-802a-93b0-fccc4f37a3b3" class="bulleted-list"><li style="list-style-type:square">y축: 확률 밀도 (점수 근처에서 답변이 나올 빈도를 나타내는 값)</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="e1ce7ce1-7d48-42d5-9412-9f39bda0859f" class="bulleted-list"><li style="list-style-type:circle">굵은 점선: 각 방법의 <strong>그리디 출력의 ROUGE-L </strong>점수</li></ul></div><div style="display:contents" dir="auto"><ul id="c2039f01-8dff-4b70-966b-f270c44ea9b5" class="bulleted-list"><li style="list-style-type:circle">(b): 두 언러닝 방법(GA vs NPO 등) 비교</li></ul></div><div style="display:contents" dir="auto"><ul id="4bdde610-0c57-46d3-b3a3-3608d8e6c6cb" class="bulleted-list"><li style="list-style-type:circle">(c): <strong>NPO vs NPO + 엔트로피 최적화(제안 방법)</strong> 비교</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8032-9796-c1e02adb27aa" class="bulleted-list"><li style="list-style-type:circle">같은 성능 점수(ROUGE)라도 분포를 까보면 NPO는 위험하고, 제안 방식(Ours)은 안전</li></ul></div><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-8092-81e2-c6efecb64624" class="">
</p></div><div style="display:contents" dir="auto"><hr id="2b407ee4-11c6-80ae-9840-d15234854a6d"/></div><div style="display:contents" dir="auto"><h3 id="2b407ee4-11c6-8054-829e-d684eb3be13a" class="">TOFU 언러닝 방법 비교: 결정론적 vs 확률적 평가</h3></div><div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-8071-8d19-ff865ea9df3b" class="image" style="text-align:center"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%2011.png"><img style="width:384px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%2011.png"/></a><figcaption>ROUGE-L, ED Score 모두 점수가 낮을수록 언러닝이 잘된 것</figcaption></figure></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2de472a2-9be2-46ea-8d29-033530d92066" class="bulleted-list"><li style="list-style-type:disc"><strong>Ours가 결정론적인 기준(Det.) 확률론적인 기준(Prob.) 모두에서 가장 좋은 성능</strong><div style="display:contents" dir="auto"><ul id="e991ff13-3c56-40e7-988f-f91ca86b9061" class="bulleted-list"><li style="list-style-type:circle"><strong>평균 유출 정도(Mean)도 가장 낮고</strong>, <strong>샘플마다 유출 정도(Std. Dev.표준편차)가 거의 변하지 않는다</strong></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-804f-b44c-f979c8fc4027" class="bulleted-list"><li style="list-style-type:disc">결정론적 언러닝 방법인 GA와 GD의 경우, 확률론적 언러닝에서의 <strong>평균(mean)이</strong> <strong>그리디 디코딩으로 얻은 ROUGE-L 점수와 거의 일치하지만 GD(0.33,0.32),GA(0.32,0.31) </strong>, 표준편차가 크다는 문제가 있음</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-807e-b89e-fdce1cd050a2" class="bulleted-list"><li style="list-style-type:disc"> 기존의 지표(RMU, GD, GA, NPO) 모두 Det.에서 언러닝이 잘 되었다고 판단했지만 확률적 지표를 통해 분포 안에 정보 누출의 위험이 아직 있음을 입증</li></ul></div><div style="display:contents" dir="auto"><hr id="2b407ee4-11c6-803d-b61b-d3a6aaa9b037"/></div><div style="display:contents" dir="auto"><h3 id="2b407ee4-11c6-80e0-ba69-fd51f16c9867" class="">엔트로피 정규화가 성능에 미치는 영향</h3></div><div style="display:contents" dir="ltr"><figure id="2b407ee4-11c6-8032-b208-df61674a178f" class="image"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%2012.png"><img style="width:709.9857788085938px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%2012.png"/></a></figure></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8027-946e-dd312032b731" class="bulleted-list"><li style="list-style-type:disc"><strong>(a): </strong>λf는 1로 고정하고 Retain 정규화 계수 λr를 0 → −0.25 방향으로 점점 더 음수로 감소<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8059-9e0f-c92f7a45aa61" class="bulleted-list"><li style="list-style-type:circle">파란 점선: NPO + 엔트로피 정규화 | 검은 점선: NPO</li></ul></div><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-80cc-bbd6-e9d47e577a81" class="">⇒ λr 값을 낮출수록(더 큰 음수로 만들수록), DRT(지켜야 할 데이터)에 대한 엔트로피 보상이 커져,  답변의 다양성(Diversity)이 증가함 </p></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80ed-8d68-fe8cb9f8868f" class="bulleted-list"><li style="list-style-type:disc"><strong>(b):</strong> epoch이 늘어날수록 DFG(지울 정보)와 DRT(지킬 정보) 사이의 확신도가 벌어짐(잘 구분함)<div style="display:contents" dir="auto"><p id="2b407ee4-11c6-80a2-9609-f6e30e822e9b" class=""> ⇒ 모델이 학습 과정에서 retain 정보와 forget 정보를 구별할 수 있음</p></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8088-acfa-e2bab21147f9" class="bulleted-list"><li style="list-style-type:disc"><strong>(c):</strong> TOFU 데이터셋의 서로 다른 분할 비율에 대해, <strong>ED score</strong>와 <strong>model utility(모델 유용성)</strong> 의 관계를 비교<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80cd-990b-fa26e48a579e" class="bulleted-list"><li style="list-style-type:circle">x축: <strong>ED score</strong></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-804a-9cf7-de444dfc4f6c" class="bulleted-list"><li style="list-style-type:circle">y축: <strong>Model Utility: </strong>retain 벤치마크(e.g., Real Authors, World Facts)에서의 성능<div style="display:contents" dir="auto"><p id="9b902de1-3c35-4117-9e11-c6f30fbe7561" class="">→ 높을수록 원래 모델의 유용성을 잘 유지함을 의미</p></div></li></ul></div><div style="display:contents" dir="auto"><ul id="29c4885b-27e7-4998-901e-e601af612790" class="bulleted-list"><li style="list-style-type:circle">TOFU 데이터 split(90/10, 95/5, 99/1) 중 하나에서 λf를 랜덤하게 설정하여  NPO + 엔트로피 정규화로 학습한 <strong>모델 하나</strong><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-80a8-94a4-d5017cd31644" class="">⇒ 실험 결과: 엔트로피 정규화를 추가하여도 언러닝을 잘 수행하면서도 모델의 전반적인 성능(Model Utility)은 떨어지지 않음</p></div></li></ul></div></li></ul></div><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-8052-8e24-d9391613c51c" class="">
</p></div><div style="display:contents" dir="auto"><h2 id="2b407ee4-11c6-8064-9c55-f7d684565dd6" class="block-color-gray_background">Preliminary</h2></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80b3-ad33-df4b3a2c9459" class="toggle"><li><details open=""><summary><strong>몬테카를로 샘플링</strong></summary><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8002-bda7-d40c004ba19b" class="bulleted-list"><li style="list-style-type:disc">몬테카를로 방법: <div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80eb-9cae-d6ff632d8b30" class="bulleted-list"><li style="list-style-type:circle">어떤 확률적인 정도를 (기댓값, 확률, 분산 등)을 직접 계산하기 복잡할 때, 그 분포에서 <strong>랜덤 표본을 여러 개 뽑아서</strong> 그 표본들로 근사하는 방법</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8005-b719-d0e7c6dc7342" class="bulleted-list"><li style="list-style-type:circle">몬테카를로 샘플링: 랜덤 표본을 뽑는 과정</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8099-884a-e785b6a8719f" class="bulleted-list"><li style="list-style-type:disc"><strong>수학적 공식으로 정확한 계산 대신 랜덤 실험을 여러 번</strong> 돌린 결과의 <strong>평균·비율</strong>로 근사</li></ul></div></details></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-808c-9655-fa5b525610f2" class="toggle"><li><details open=""><summary><strong>베르누이 확률 변수</strong></summary><div style="display:contents" dir="ltr"><figure id="2b607ee4-11c6-801b-ad81-e854c44a4ee9" class="image"><a href="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%2013.png"><img style="width:384px" src="../../blog/a-probabilistic-perspective-on-unlearning-and-alignment-for-large-language-models/image%2013.png"/></a></figure></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8076-95e0-dde82e96714a" class="bulleted-list"><li style="list-style-type:disc">결과가 딱 두 가지밖에 없는 실험 e.g., 동전 던지기</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8050-9ca8-d9358877cfd3" class="bulleted-list"><li style="list-style-type:disc">결과 값은 0 또는 1 뿐. 1이 나올 확률을 p, 아닌 확률을 1-p라고 정의</li></ul></div></details></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-803e-80ef-c173cf33f68c" class="toggle"><li><details open=""><summary><strong>샘플링 기반 디코딩</strong></summary><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-804e-9c81-d4395c5e9903" class="bulleted-list"><li style="list-style-type:disc">LLM이 다음 단어를 확률적으로 선택하여 문장을 만드는 방식</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80c4-9c7b-d7a440771b52" class="bulleted-list"><li style="list-style-type:disc">그리디 디코딩: 가장 높은 확률만 선택</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8006-ae2a-f9d126cf5be5" class="bulleted-list"><li style="list-style-type:disc">샘플링 기반 디코딩: 확률에 비례해서 랜덤으로 선택</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8033-a09f-e1b148b54b19" class="bulleted-list"><li style="list-style-type:disc"> </li></ul></div></details></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8011-bdd0-e5e5b4436d15" class="toggle"><li><details open=""><summary><strong>Next Word Prediction (Greedy Decoding/Beam Search/Multinomial Sampling)</strong></summary><div style="display:contents" dir="ltr"><table id="2b407ee4-11c6-80ee-a0a1-dd1baf90b65e" class="simple-table"><tbody><div style="display:contents" dir="ltr"><tr id="2b407ee4-11c6-8061-bb56-c32aa431df56"><td id="~uPN" class="" style="width:160.5283966064453px"><strong>전략 (용어)</strong></td><td id="bDzA" class="" style="width:256.99737548828125px"><strong>핵심 아이디어</strong></td><td id="[\ks" class="" style="width:207.8828125px"><strong>답변의 특징</strong></td></tr></div><div style="display:contents" dir="ltr"><tr id="2b407ee4-11c6-80c6-9677-e53524b9820b"><td id="~uPN" class="" style="width:160.5283966064453px"><strong>Greedy Decoding</strong></td><td id="bDzA" class="" style="width:256.99737548828125px">매 순간 확률 1위 단어만 선택 </td><td id="[\ks" class="" style="width:207.8828125px">항상 <strong>똑같은</strong> 답변 (결정론적)</td></tr></div><div style="display:contents" dir="ltr"><tr id="2b407ee4-11c6-80e1-a25c-ff193383daae"><td id="~uPN" class="" style="width:160.5283966064453px"><strong>Multinomial Sampling</strong></td><td id="bDzA" class="" style="width:256.99737548828125px">확률에 따라 <strong>무작위</strong> 선택</td><td id="[\ks" class="" style="width:207.8828125px">매번 <strong>다른</strong> 답변 (확률론적)</td></tr></div><div style="display:contents" dir="ltr"><tr id="2b407ee4-11c6-801e-a4c5-dd9590c70caf"><td id="~uPN" class="" style="width:160.5283966064453px"><strong>Beam Search</strong></td><td id="bDzA" class="" style="width:256.99737548828125px">가장 유력한 문장 <strong>후보 3~5개</strong>를 동시 탐색</td><td id="[\ks" class="" style="width:207.8828125px">Greedy보다 높은 품질, 일관성 </td></tr></div></tbody></table></div><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-800d-8835-d404d48de510" class="numbered-list" start="1"><li><strong>Greedy Decoding (결정론)</strong><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8038-b321-d8ce66eddeb7" class="bulleted-list"><li style="list-style-type:disc">가장 좋은 것 <strong>하나만 선택</strong> → 매 순간, 모델이 생각하는 가장 확률이 높은 단어를 선택</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-806e-a8fa-cece88ea9579" class="bulleted-list"><li style="list-style-type:disc"><strong>결정론적 </strong>→ 몇 번을 물어봐도 같은 응답 출력</li></ul></div></li></ol></div><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-8018-b282-e6ae9d615a4f" class="numbered-list" start="2"><li><strong>Beam Search (중간)</strong><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-801a-9a15-e476247dfab3" class="bulleted-list"><li style="list-style-type:disc">가장 유력한 후보 몇 개만 남기기 (greedy와 sampling의 중간)</li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8021-a0d1-d0ad00a0f749" class="bulleted-list"><li style="list-style-type:disc">가장 그럴듯한 문장 후보를 빔(Beam)이라 부르는 3~5개만 남기고 계속 탐색</li></ul></div></li></ol></div><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-80e6-a56a-f5d5d4d9ff9a" class="numbered-list" start="3"><li><strong>Multinomial Sampling (무작위 확률)</strong><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80bc-85a5-e3bb39a65ed0" class="bulleted-list"><li style="list-style-type:disc">확률 분포를 바탕으로 <strong>무작위 선택</strong> </li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8045-bf7b-fc55064574c7" class="bulleted-list"><li style="list-style-type:disc"><strong>확률론적 </strong>→ <strong>매번 결과가 다를 수 있음</strong></li></ul></div></li></ol></div></details></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80e7-b791-dfb2355dd218" class="toggle"><li><details open=""><summary><strong>NPO (Negative Preference Optimization, 부정 선호 최적화)</strong></summary><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-800c-b3a4-c6b1df48d856" class="bulleted-list"><li style="list-style-type:disc">목표: 이런 답은 싫다(원하지 않는다)는 예제를 이용해서 모델이 그 답을 덜 출력하도록 학습<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80f4-8842-ffbeac5cddf6" class="bulleted-list"><li style="list-style-type:circle">기존 RLHF(인간 피드백 미세조정)<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-80a3-98dc-cfe4f26470ec" class="bulleted-list"><li style="list-style-type:square">좋은 답은 보상을 높게 줘서 자주 나오게 만들고 나쁜 답은 보상을 낮게 줘서 덜 나오도록</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><p id="2b407ee4-11c6-80e3-ad3b-f3ca5dc78a7c" class=""><strong>  ⇒ 언러닝에서는 나쁜 답에 대한 선호를 낮추는 (push down) 최적화</strong></p></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8087-8a1f-e9c7532f9dea" class="bulleted-list"><li style="list-style-type:disc">학습 구조<div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-8020-90ea-d8ec94862a99" class="numbered-list" start="1"><li>질문–답 쌍 (x,y) → x: 프롬프트 (질문), y: 지워야 하는 정답 (forget 정답)<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8090-9cc3-fb753663316a" class="bulleted-list"><li style="list-style-type:disc">e.g., “Alex Bloom은 1995년 3월 5일에 태어났다.”</li></ul></div></li></ol></div><div style="display:contents" dir="auto"><ol type="1" id="2b407ee4-11c6-807e-8091-cd29dee9e545" class="numbered-list" start="2"><li>잊어야 할 데이터를 생성하려고 할 때마다 부정적인 점수(손실, Loss) 부여하여 모델이 해당 데이터를 싫어하도록 유도<div style="display:contents" dir="auto"><ul id="2b407ee4-11c6-8026-97b0-ea1292cdef8c" class="bulleted-list"><li style="list-style-type:disc">−log⁡πθ(y∣x) (손실)를 <strong>maximize</strong> 하는 쪽으로 학습</li></ul></div></li></ol></div></li></ul></div></details></li></ul></div><div style="display:contents" dir="auto"><p id="2b507ee4-11c6-80be-9807-d521ca8780d9" class="">
</p></div></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>